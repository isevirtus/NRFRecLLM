{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f6f966-cf74-4722-9d5c-f1f0436952dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4532f0d1-620d-46d3-954c-55531fb63faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminho_json = \"results\\\\response.json\"\n",
    "\n",
    "resposta = defaultdict(list)\n",
    "\n",
    "'''\n",
    "    --> Pegando os dados de resposta do chatGPT\n",
    "'''\n",
    "with open(caminho_json, encoding='utf-8') as f:\n",
    "    dados = json.load(f)\n",
    "\n",
    "for item in dados:\n",
    "    chave = (item[\"Projeto\"], item[\"Sprint_ID\"], item[\"US_ID\"])\n",
    "    resposta[chave].append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1a322a3-26ad-4bb4-a26e-91167fa4bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    --> Pegando os dados de resposta da base\n",
    "'''\n",
    "base = defaultdict(list)\n",
    "caminho_csv = \"Data\\\\dados_processados_projetos_final.csv\"\n",
    "\n",
    "with open(caminho_csv, newline='', encoding='utf-8') as csvfile:\n",
    "    leitor = csv.DictReader(csvfile)\n",
    "    for linha in leitor:\n",
    "        chave = (linha[\"Projeto\"], linha[\"Sprint_ID\"], linha[\"US_ID\"])\n",
    "        base[chave].append(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9d38e9d-3feb-4025-92cd-3658bbdeac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "print(len(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93971b20-62ca-4b23-8e0d-c996270248f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabecalhos = [\n",
    "    \"Project_ID\", \"Project_name\", \"Sprint_ID\", \"US_ID\", \"Tarefas_IDS\",\n",
    "    \"LLM Model\", \"NFR Recommended (ground thuth)\", \"NFR Suggested by LLM\", \"NFR_agreements\", \"NFR_disagreements\",\n",
    "    \"Precision\", \"Recall\", \"F-measure\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f12b4e56-dbca-469d-90a6-85e6d0c53639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1126\n"
     ]
    }
   ],
   "source": [
    "resultados_acumulados = []\n",
    "quantidade_tasks = 0\n",
    "\n",
    "for chave, tasks in base.items():\n",
    "    try:\n",
    "        if isinstance(chave, tuple) and len(chave) == 3:\n",
    "            projeto, sprint, us = chave\n",
    "            \n",
    "            # Variáveis para contagem\n",
    "            nfrs_base_unicos = set()  # Armazena NFRs únicos da base (para evitar repetições)\n",
    "            tarefas_ids = []\n",
    "            acertou = 0\n",
    "            errou = 0\n",
    "            sem_nfr = 0\n",
    "\n",
    "            # Carrega os NFRs sugeridos pelo LLM (já são únicos)\n",
    "            resposta_completa = resposta[(projeto, sprint, us)][0]\n",
    "            lista_nfrs = json.loads(resposta_completa['Resposta'])\n",
    "            nfrs_llm = {(nfr[\"NFR_Tipo\"], nfr[\"NFR_Atributo\"]) for nfr in lista_nfrs}  # Conjunto de NFRs do LLM\n",
    "\n",
    "            # Processa cada tarefa da base\n",
    "            for j in base[(projeto, sprint, us)]:\n",
    "                quantidade_tasks += 1\n",
    "                tarefas_ids.append(f\"{j['Tarefa_ID']} | \")\n",
    "                \n",
    "                # Verifica se é um NFR válido (não é \"1\")\n",
    "                if (j[\"NFR_Tipo\"] != \"1\") and (j[\"NFR_Atributo\"] != \"1\"):\n",
    "                    nfr_key = (j[\"NFR_Tipo\"], j[\"NFR_Atributo\"])\n",
    "                    \n",
    "                    # Conta cada NFR da base APENAS UMA VEZ por US/Sprint\n",
    "                    if nfr_key not in nfrs_base_unicos:\n",
    "                        nfrs_base_unicos.add(nfr_key)\n",
    "                        \n",
    "                        # Verifica se o NFR está nas sugestões do LLM\n",
    "                        if nfr_key in nfrs_llm:\n",
    "                            acertou += 1\n",
    "                else:\n",
    "                    sem_nfr += 1\n",
    "\n",
    "            # Cálculo das métricas\n",
    "            total_nfr_base = len(nfrs_base_unicos)  # NFRs únicos da base\n",
    "            total_nfr_llm = len(nfrs_llm)          # NFRs sugeridos pelo LLM (únicos por padrão)\n",
    "            \n",
    "            precision = acertou / total_nfr_llm if total_nfr_llm > 0 else 0\n",
    "            recall = acertou / total_nfr_base if total_nfr_base > 0 else 0\n",
    "            f_measure = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "            novo_item = {\n",
    "                \"Project_ID\": j[\"Projeto_ID\"],\n",
    "                \"Project_name\": j[\"Projeto\"],\n",
    "                \"Sprint_ID\": j[\"Sprint_ID\"],\n",
    "                \"US_ID\": j[\"US_ID\"],\n",
    "                \"Tarefas_IDS\": \"\".join(tarefas_ids).strip(\" | \"),  # Junta IDs e remove o último separador\n",
    "                \"LLM Model\": \"gpt-4.1-mini\",\n",
    "                \"NFR Recommended (ground thuth)\": total_nfr_base,\n",
    "                \"NFR Suggested by LLM\": total_nfr_llm,\n",
    "                \"NFR_agreements\": acertou,\n",
    "                \"NFR_disagreements\": total_nfr_llm - acertou,\n",
    "                \"Precision\": round(precision, 2),\n",
    "                \"Recall\": round(recall, 2),\n",
    "                \"F-measure\": round(f_measure, 2)\n",
    "            }\n",
    "            resultados_acumulados.append(novo_item)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Erro ao processar a chave {chave}: {e}\")\n",
    "\n",
    "print(quantidade_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a4ef3d2-1fcc-4bf4-95cb-38a84099cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results\\\\results_final.csv\", mode=\"a\", newline=\"\", encoding=\"utf-8\") as arquivo:\n",
    "    writer = csv.DictWriter(arquivo, fieldnames=cabecalhos)\n",
    "    \n",
    "    if arquivo.tell() == 0:\n",
    "        writer.writeheader()\n",
    "    \n",
    "    writer.writerows(resultados_acumulados) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
